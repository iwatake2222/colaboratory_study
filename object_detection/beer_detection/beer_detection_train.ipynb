{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "beer_detection_train",
      "provenance": [],
      "collapsed_sections": [
        "KVHOcPtEK145",
        "9MbtFu_sbFFV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iwatake2222/colaboratory_study/blob/master/object_detection/beer_detection/beer_detection_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7HYRZ5ulnUM",
        "colab_type": "text"
      },
      "source": [
        "# Object detection model training\n",
        "- dataset: beer (tfrecord)\n",
        "- pretrained model: faster_rcnn_resnet101_coco, ssd_mobilenet_v2_quantized_300x300_coco\n",
        "  - config files (modify and upload to google drive)\n",
        "    - https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_resnet101_coco.config\n",
        "    - https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config\n",
        "  - pretrained models (https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md )\n",
        "    - http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2018_01_28.tar.gz\n",
        "    - http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\n",
        "\n",
        "- note\n",
        "  - need to decrease the number of batch_size in config file, otherwise OOM occurs\n",
        "  - find `### MODIFY ###` in the config file and scripts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuxKlVGPl7Sr",
        "colab_type": "text"
      },
      "source": [
        "# Preparation\n",
        "## Setting for environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBG7Y4_aI5sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Hquh_fJTaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "!pip install pycocotools\n",
        "!pip list\n",
        "\n",
        "!git clone --depth 1 https://github.com/tensorflow/models\n",
        "%cd models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!pip install .\n",
        "%cd /content\n",
        "\n",
        "# Modify python path and check script\n",
        "%set_env PYTHONPATH=$PYTHONPATH:models/research:models/research/slim\n",
        "!echo $PYTHONPATH\n",
        "!python models/research/object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB6gS-czA2Ue",
        "colab_type": "text"
      },
      "source": [
        "# Setting for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP4aeHnrGT9o",
        "colab_type": "text"
      },
      "source": [
        "## Get training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlcF-NvtzAs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "### MODIFY ### (depending on dataset)\n",
        "FILE_ID=1-3M4Thwd3tH0XYglvaKwnpakjFrgR2gr\n",
        "FILE_NAME=dataset_beer.tar.gz\n",
        "\n",
        "curl -sc /tmp/cookie \"https://drive.google.com/uc?export=download&id=${FILE_ID}\" > /dev/null\n",
        "CODE=\"$(awk '/_warning_/ {print $NF}' /tmp/cookie)\"  \n",
        "curl -Lb /tmp/cookie \"https://drive.google.com/uc?export=download&confirm=${CODE}&id=${FILE_ID}\" -o ${FILE_NAME}\n",
        "tar -xvf ${FILE_NAME}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LuXN3b_0SkF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b26bdc7a-b0a8-49d0-d41c-7cc72ac057ef"
      },
      "source": [
        "### MODIFY ### (if needed)\n",
        "DATASET_ORG_DIR = \"/content/dataset_beer\"\n",
        "DATASET_TRAIN = \"/content/dataset/train\"\n",
        "DATASET_EVAL = \"/content/dataset/eval\"\n",
        "\n",
        "!rm -rf  \"$DATASET_TRAIN\" && mkdir -p \"$DATASET_TRAIN\"\n",
        "!rm -rf  \"$DATASET_EVAL\" && mkdir -p \"$DATASET_EVAL\"\n",
        "!cp \"$DATASET_ORG_DIR/tf_label_map.pbtxt\" \"$DATASET_TRAIN/../.\"\n",
        "\n",
        "import random\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "img_list = glob.glob(DATASET_ORG_DIR + \"/tfrecord/*.tfrecord\")\n",
        "files_train = set(random.sample(\n",
        "  img_list,\n",
        "  int(len(img_list)*.7)\n",
        "))\n",
        "files_eval = set(img_list) - file_to_dir1\n",
        "for f in files_train:\n",
        "  shutil.copy(f, DATASET_TRAIN)\n",
        "\n",
        "for f in files_eval:\n",
        "  shutil.copy(f, DATASET_EVAL)\n",
        "\n",
        "!ls -1 \"$DATASET_TRAIN\" | wc -l\n",
        "!ls -1 \"$DATASET_EVAL\" | wc -l"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137\n",
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZKeiisbrhWr",
        "colab_type": "text"
      },
      "source": [
        "## Get pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f54V5YQTY1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### MODIFY ### (depending on pretrained model)\n",
        "# PRETRAINED_MODEL_URL =  \"http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz\"\n",
        "PRETRAINED_MODEL_URL =  \"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz\"\n",
        "PRETRAINED_MODEL_DIR = \"/content/dataset/pretrained_model\"\n",
        "\n",
        "!wget \"$PRETRAINED_MODEL_URL\" -O pretrained_model.tar.gz\n",
        "!rm -rf \"$PRETRAINED_MODEL_DIR\" && mkdir -p \"$PRETRAINED_MODEL_DIR\"\n",
        "!tar -xvf pretrained_model.tar.gz -C \"$PRETRAINED_MODEL_DIR\" --strip-components 1\n",
        "!ls \"$PRETRAINED_MODEL_DIR\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNJTmrXTCwpG",
        "colab_type": "text"
      },
      "source": [
        "## Get config file\n",
        "https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV3IoWMwyKrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### MODIFY ### (depending on training)\n",
        "# TRAIN_DIR = \"/content/drive/My Drive/training/beer_detection/faster_rcnn_resnet101_coco_11_06_2017_20191230\"\n",
        "# ORIGINAL_CONFIG_FILE = \"faster_rcnn_resnet101_coco.config\"\n",
        "# CONFIG_FILE = \"/faster_rcnn_resnet101_beer.config\"\n",
        "TRAIN_DIR = \"/content/drive/My Drive/training/beer_detection/ssd_mobilenet_v2_quantized_300x300_coco_20200104\"\n",
        "ORIGINAL_CONFIG_FILE = \"ssd_mobilenet_v2_quantized_300x300_coco.config\"\n",
        "CONFIG_FILE = \"/ssd_mobilenet_v2_quantized_300x300_beer.config\"\n",
        "\n",
        "!mkdir -p \"$TRAIN_DIR\"\n",
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/samples/configs/\"$ORIGINAL_CONFIG_FILE\" -P \"$TRAIN_DIR\"\n",
        "!cp \"$TRAIN_DIR/$ORIGINAL_CONFIG_FILE\" \"$TRAIN_DIR/$CONFIG_FILE\" \n",
        "!cp \"$DATASET_ORG_DIR/tf_label_map.pbtxt\" \"$TRAIN_DIR/.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGwGwxPYmX1e",
        "colab_type": "text"
      },
      "source": [
        "## Edit config file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVHOcPtEK145",
        "colab_type": "text"
      },
      "source": [
        "### faster_rcnn_resnet101_beer.config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEk1bmm7K4AM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# Faster R-CNN with Resnet-101 (v1), configuration for MSCOCO Dataset.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  faster_rcnn {\n",
        "    ### MODIFY ###\n",
        "    num_classes: 10\n",
        "    image_resizer {\n",
        "      keep_aspect_ratio_resizer {\n",
        "        min_dimension: 600\n",
        "        max_dimension: 1024\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'faster_rcnn_resnet101'\n",
        "      first_stage_features_stride: 16\n",
        "    }\n",
        "    first_stage_anchor_generator {\n",
        "      grid_anchor_generator {\n",
        "        scales: [0.25, 0.5, 1.0, 2.0]\n",
        "        aspect_ratios: [0.5, 1.0, 2.0]\n",
        "        height_stride: 16\n",
        "        width_stride: 16\n",
        "      }\n",
        "    }\n",
        "    first_stage_box_predictor_conv_hyperparams {\n",
        "      op: CONV\n",
        "      regularizer {\n",
        "        l2_regularizer {\n",
        "          weight: 0.0\n",
        "        }\n",
        "      }\n",
        "      initializer {\n",
        "        truncated_normal_initializer {\n",
        "          stddev: 0.01\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    first_stage_nms_score_threshold: 0.0\n",
        "    first_stage_nms_iou_threshold: 0.7\n",
        "    first_stage_max_proposals: 300\n",
        "    first_stage_localization_loss_weight: 2.0\n",
        "    first_stage_objectness_loss_weight: 1.0\n",
        "    initial_crop_size: 14\n",
        "    maxpool_kernel_size: 2\n",
        "    maxpool_stride: 2\n",
        "    second_stage_box_predictor {\n",
        "      mask_rcnn_box_predictor {\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 1.0\n",
        "        fc_hyperparams {\n",
        "          op: FC\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.0\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            variance_scaling_initializer {\n",
        "              factor: 1.0\n",
        "              uniform: true\n",
        "              mode: FAN_AVG\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    second_stage_post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 0.0\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        ### MODIFY ###\n",
        "        max_total_detections: 100\n",
        "      }\n",
        "      score_converter: SOFTMAX\n",
        "    }\n",
        "    second_stage_localization_loss_weight: 2.0\n",
        "    second_stage_classification_loss_weight: 1.0\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 1\n",
        "  optimizer {\n",
        "    momentum_optimizer: {\n",
        "      learning_rate: {\n",
        "        manual_step_learning_rate {\n",
        "          initial_learning_rate: 0.0003\n",
        "          schedule {\n",
        "            step: 900000\n",
        "            learning_rate: .00003\n",
        "          }\n",
        "          schedule {\n",
        "            step: 1200000\n",
        "            learning_rate: .000003\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "    }\n",
        "    use_moving_average: false\n",
        "  }\n",
        "  gradient_clipping_by_norm: 10.0\n",
        "  ### MODIFY ###\n",
        "  fine_tune_checkpoint: \"/content/dataset/pretrained_model/model.ckpt\"\n",
        "  from_detection_checkpoint: true\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  ### MODIFY ###\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/dataset/train/*.tfrecord\"\n",
        "  }\n",
        "  label_map_path: \"/content/dataset/tf_label_map.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  num_examples: 8000\n",
        "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  max_evals: 10\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  ### MODIFY ###\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/dataset/eval/*.tfrecord\"\n",
        "  }\n",
        "  label_map_path: \"/content/dataset/tf_label_map.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MbtFu_sbFFV",
        "colab_type": "text"
      },
      "source": [
        "### ssd_mobilenet_v2_quantized_300x300_beer.config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S71bs6HbLvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "# Quantized trained SSD with Mobilenet v2 on MSCOCO Dataset.\n",
        "# Users should configure the fine_tune_checkpoint field in the train config as\n",
        "# well as the label_map_path and input_path fields in the train_input_reader and\n",
        "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
        "# should be configured.\n",
        "\n",
        "model {\n",
        "  ssd {\n",
        "    ### MODIFY ###\n",
        "    num_classes: 10\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    image_resizer {\n",
        "      fixed_shape_resizer {\n",
        "        height: 300\n",
        "        width: 300\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 1\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.00004\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.9997,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v2'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.00004\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.9997,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "        num_hard_examples: 3000\n",
        "        iou_threshold: 0.99\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  ### MODIFY ###\n",
        "  batch_size: 10\n",
        "  optimizer {\n",
        "    rms_prop_optimizer: {\n",
        "      learning_rate: {\n",
        "        exponential_decay_learning_rate {\n",
        "          initial_learning_rate: 0.004\n",
        "          decay_steps: 800720\n",
        "          decay_factor: 0.95\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "      decay: 0.9\n",
        "      epsilon: 1.0\n",
        "    }\n",
        "  }\n",
        "  ### MODIFY ###\n",
        "  fine_tune_checkpoint: \"/content/dataset/pretrained_model/model.ckpt\"\n",
        "  fine_tune_checkpoint_type:  \"detection\"\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 200000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  ### MODIFIED ###\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/dataset/train/*.tfrecord\"\n",
        "  }\n",
        "  label_map_path: \"/content/dataset/tf_label_map.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  num_examples: 8000\n",
        "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  max_evals: 10\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  ### MODIFIED ###\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/dataset/eval/*.tfrecord\"\n",
        "  }\n",
        "  label_map_path: \"/content/dataset/tf_label_map.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}\n",
        "\n",
        "graph_rewriter {\n",
        "  quantization {\n",
        "    delay: 48000\n",
        "    weight_bits: 8\n",
        "    activation_bits: 8\n",
        "  }\n",
        "}\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF8FHES4EFv4",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX0Na4v3j1y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path=\"$TRAIN_DIR/$CONFIG_FILE\" \\\n",
        "    --model_dir=\"$TRAIN_DIR\" \\\n",
        "    --num_train_steps=10000 \\\n",
        "    --num_eval_steps=2000 \\\n",
        "    --alsologtostderr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn0ojj0VpLQ-",
        "colab_type": "text"
      },
      "source": [
        "# Export graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtXy1-JuAzy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this doesn't work for tflite conversion\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=\"$TRAIN_DIR/$CONFIG_FILE\" \\\n",
        "    --trained_checkpoint_prefix=\"$TRAIN_DIR/model.ckpt-10000\" \\\n",
        "    --output_directory=\"$TRAIN_DIR/exported_graphs\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqRZIVvzLZ-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use this instead for tflite conversion\n",
        "!python models/research/object_detection/export_tflite_ssd_graph.py\t\\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=\"$TRAIN_DIR/$CONFIG_FILE\" \\\n",
        "    --trained_checkpoint_prefix=\"$TRAIN_DIR/model.ckpt-10000\" \\\n",
        "    --output_directory=\"$TRAIN_DIR/exported_graphs\" \\\n",
        "    --add_postprocessing_op=true\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpmtJUU8pRey",
        "colab_type": "text"
      },
      "source": [
        "## Check model structure\n",
        "to identify input and output nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJqqFcnoYqtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Graph = tf.GraphDef()\n",
        "# File = open(TRAIN_DIR + \"/exported_graphs/frozen_inference_graph.pb\",\"rb\")\n",
        "File = open(TRAIN_DIR + \"/exported_graphs/tflite_graph.pb\",\"rb\")\n",
        "Graph.ParseFromString(File.read())\n",
        "for Layer in Graph.node:\n",
        "  print(Layer.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2npzS7O-paaT",
        "colab_type": "text"
      },
      "source": [
        "## Convert to tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0zXCkEmOz4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_arrays = [\"normalized_input_image_tensor\"]\n",
        "converter = tf.lite.TFLiteConverter.from_frozen_graph(\n",
        "  TRAIN_DIR + \"/exported_graphs/tflite_graph.pb\",\n",
        "  input_arrays,\n",
        "  [\"TFLite_Detection_PostProcess\", \"TFLite_Detection_PostProcess:1\", \"TFLite_Detection_PostProcess:2\", \"TFLite_Detection_PostProcess:3\"],\n",
        "  input_shapes={input_arrays[0]:[1,300,300,3]}\n",
        ")\n",
        "\n",
        "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.allow_custom_ops=True\n",
        "converter.inference_input_type = tf.lite.constants.QUANTIZED_UINT8\n",
        "# converter.inference_output_type = tf.lite.constants.QUANTIZED_UINT8\n",
        "converter.quantized_input_stats = {input_arrays[0] : (128., 127.)}  # mean, std_dev ((quantized_input_value - mean_value) / std_dev_value.)\n",
        "converter.default_ranges_stats = (-10, 10)\n",
        "converter.inference_type = tf.lite.constants.QUANTIZED_UINT8\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "open(TRAIN_DIR + \"/exported_graphs/beer_mobilenet_v2_quantized_300x300.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNEhupVGLtzU",
        "colab_type": "text"
      },
      "source": [
        "### Convert for edge TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA9kUO6AaxAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash \n",
        "curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "sudo apt-get update\n",
        "sudo apt-get install edgetpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol-LUbgTLsMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!edgetpu_compiler \"$TRAIN_DIR/exported_graphs/beer_mobilenet_v2_quantized_300x300.tflite\"\n",
        "!cp beer_mobilenet_v2_quantized_300x300_edgetpu.tflite \"$TRAIN_DIR/exported_graphs/.\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}