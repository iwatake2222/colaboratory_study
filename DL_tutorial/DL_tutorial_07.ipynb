{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_tutorial_07.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrxtTR77OZUti5IMfK/f7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iwatake2222/colaboratory_study/blob/master/DL_tutorial/DL_tutorial_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxBrB0XlO_xg",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learningアプリケーション開発 (7) TensorFlow Lite with Python on Raspberry Pi and Edge TPU\n",
        "Post-training quantizationしたTensorFlow LiteモデルをEdge TPU上で動かしてみる\n",
        "\n",
        "https://qiita.com/iwatake2222/items/6aeab468c326ecc21563\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4BRXsuBSCyf",
        "colab_type": "text"
      },
      "source": [
        "# 環境設定\n",
        "It's better to use tensorflow 1.15 because it supports full integer post-training quantization.\n",
        "\n",
        "You can still use tensorflow 2.x although it doesn't support full integer post-training quantization (fp32 to int8 conversion ops will be added to input/output), and the converted model may not work on Edge TPU though.\n",
        "In case you want to use Tensorflow 2.x, you need to use tf-nightly(Tensorflow2.2). Otherwise the following error happend when converting to tflite\n",
        "\n",
        "```\n",
        "ValueError: Failed to parse the model: /tensorflow-2.1.0/python3.6/tensorflow_core/lite/python/optimize/_tensorflow_lite_wrap_calibration_wrapper.so: undefined symbol: _ZTIN10tensorflow6DeviceE.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noVg-PdLXdxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls\n",
        "\n",
        "# Install EdgeTPU\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt -y update\n",
        "!sudo apt -y install edgetpu\n",
        "\n",
        "# Use Tensorflow 2.2.0, instead of tensorflow-2.1.0rc1\n",
        "# %tensorflow_version 2.x\n",
        "# !pip3 uninstall -y tensorflow\n",
        "# !pip3 install tf-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X4ZmayPn1Ox",
        "colab_type": "text"
      },
      "source": [
        "# モデル変換 (Keras(H5) -> Quantized Tensorflow Lite Model(tflite))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AB-biDngArt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "# Download Keraas model\n",
        "# https://drive.google.com/open?id=1H7zKhgxdS6eiaMzxsyON9Wtne-pVnjXL\n",
        "!wget -O conv_mnist.h5 \"https://drive.google.com/uc?export=download&id=1OLR1n5Pq0CGPz7Bw5pad-fvYsgCnKvHh\"\n",
        "\n",
        "## Prepara dataset generator for calibration\n",
        "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_train = x_train / 255.0\n",
        "x_train = x_train.astype(np.float32)\n",
        "num_calibration_images = 100\n",
        "calibration_indexes   = np.random.choice(x_train.shape[0], num_calibration_images, replace=False)\n",
        "def representative_dataset_gen():\n",
        "  for i in range(num_calibration_images):\n",
        "    yield [x_train[calibration_indexes[i: i + 1]]]\n",
        "\n",
        "\n",
        "# Convert\n",
        "# loaded_model = tf.keras.models.load_model(\"conv_mnist.h5\")\n",
        "# converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model_file(\"conv_mnist.h5\")\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter.experimental_new_converter = True   # will be no need in the future\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "open(\"conv_mnist_quant.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "!edgetpu_compiler conv_mnist_quant.tflite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84RMZztqBI1d",
        "colab_type": "text"
      },
      "source": [
        "# モデル変換 (Tensorflow Saved Model(pb) -> Quantized Tensorflow Lite Model(tflite))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQEi-myrBJfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "# Download Saved model\n",
        "!wget -O conv_mnist_saved_model.tar.gz \"https://drive.google.com/uc?export=download&id=1T0_2UYERZkTQnBZ4ocfnT7j1u0XJ2xKm\"\n",
        "!tar zxvf conv_mnist_saved_model.tar.gz\n",
        "saved_model_dir = \"./conv_mnist_saved_model\"\n",
        "\n",
        "## Prepara dataset generator for calibration\n",
        "(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_train = x_train / 255.0\n",
        "x_train = x_train.astype(np.float32)\n",
        "num_calibration_images = 100\n",
        "calibration_indexes   = np.random.choice(x_train.shape[0], num_calibration_images, replace=False)\n",
        "def representative_dataset_gen():\n",
        "  for i in range(num_calibration_images):\n",
        "    yield [x_train[calibration_indexes[i: i + 1]]]\n",
        "\n",
        "\n",
        "# Convert\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "converter.experimental_new_converter = True   # will be no need in the future\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "open(\"conv_mnist_quant.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "!edgetpu_compiler conv_mnist_quant.tflite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rleTROGWFbPY",
        "colab_type": "text"
      },
      "source": [
        "# TFLiteモデルによる推論テスト\n",
        "may not work on Tensorflow 1.15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCNSwePwmYKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Read input image\n",
        "!wget -O 4.jpg  \"https://drive.google.com/uc?export=download&id=1-3yb3qCrN8M6Bdj7ZZ9UMjONh34R2W_A\" \n",
        "img = cv2.imread(\"4.jpg\")\n",
        "cv2_imshow(img)\n",
        "\n",
        "# Pre process\n",
        "## グレースケール化、リサイズ、白黒反転、価範囲を0～255 -> 0.0～1.0\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img = cv2.resize(img, (28, 28))\n",
        "img = 255 - img\n",
        "# img = img / 255.\n",
        "# img = img.astype(np.float32)\n",
        "img = img.astype(np.uint8)\n",
        "input_tensor = img.reshape(1, img.shape[0], img.shape[1], 1)\n",
        "input_tensor = tf.convert_to_tensor(input_tensor)\n",
        "\n",
        "\n",
        "# Load model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"conv_mnist_quant.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# set input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
        "\n",
        "# Inference\n",
        "interpreter.invoke()\n",
        "\n",
        "scores = interpreter.get_tensor(output_details[0]['index'])\n",
        "result = np.argmax(scores[0])\n",
        "print(\"predicted number is {} [{:.2f}]\".format(result, scores[0][result]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFq7QP1Uo0kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save to google drive\n",
        "!cp *.tflite  \"/content/drive/My Drive/test_data/number/.\"\n",
        "\n",
        "# Download to local\n",
        "from google.colab import files\n",
        "files.download( \"./conv_mnist_quant.tflite\")\n",
        "files.download( \"./conv_mnist_quant_edgetpu.tflite\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}